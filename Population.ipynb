{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sudden-fetish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"2\"\n",
    "\n",
    "#toggle if GPU runs out of memory\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime, os\n",
    "import cv2, pickle, time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import scipy.optimize as optimize\n",
    "import glob\n",
    "import pandas as pd\n",
    "import tifffile as tiff\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "material-snake",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = np.array([3,4,5,4,4,5,3,5,5,4,4])\n",
    "creds_ = np.array([4,4,4,3,4,4,3,4,4,3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "resident-sunrise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.225"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5*4*4 + 4*2*4 + 4*3*3 + 3*1*4 + 3*1*3)/sum(creds_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "quarterly-switzerland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './chkp/pop_pred/final/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 2048000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 10, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "def conv_layer(feat, filters, kernel_size, strides, training, reg = None, act_reg = None, name = None, trainable = True, padding = \"same\", relu = True):\n",
    "    conv = tf.compat.v1.layers.Conv2D(filters=filters,\n",
    "                            kernel_size=kernel_size,\n",
    "                            strides=strides,\n",
    "                            padding=padding,\n",
    "                            name=name,\n",
    "                            trainable=trainable,\n",
    "                            kernel_regularizer=reg,\n",
    "                            activity_regularizer=act_reg)(feat)\n",
    "\n",
    "    bn = tf.compat.v1.layers.batch_normalization(conv, center=True, scale=True, training=training)\n",
    "    \n",
    "    if relu:\n",
    "        return tf.nn.leaky_relu(bn, alpha=0.1)\n",
    "    else:\n",
    "        return bn\n",
    " \n",
    "def pooling(feat):\n",
    "    return tf.compat.v1.layers.MaxPooling2D(pool_size=3, strides=2)(feat)\n",
    "\n",
    "def resnet_block(feat, filters, kernel_size, strides, training, reg, relu = True, trainable = True):\n",
    "    conv = tf.compat.v1.layers.Conv2D(filters,kernel_size,strides,padding=\"same\", trainable = trainable, kernel_regularizer=reg)(feat)\n",
    "    bn = tf.compat.v1.layers.batch_normalization(conv, training=training, trainable = trainable)\n",
    "    if relu:\n",
    "        return tf.nn.leaky_relu(bn, alpha=0.1)\n",
    "    else:\n",
    "        return bn\n",
    "\n",
    "def block(feat, filters, training, reg=None, stride = 1):\n",
    "\n",
    "    conv0 = resnet_block(feat, filters, 1, stride, training, reg)\n",
    "    conv1 = resnet_block(conv0, filters, 3, 1, training, reg)\n",
    "\n",
    "    if feat.shape[-1] == filters*4:\n",
    "        conv2 = resnet_block(conv1, filters*4, 1, 1, training, reg, relu = False) + feat\n",
    "    else:\n",
    "        conv2 = resnet_block(conv1, filters*4, 1, 1, training, reg, relu = False) + \\\n",
    "                resnet_block(feat, filters*4, 1, stride, training, reg, relu = False)\n",
    "    return tf.nn.leaky_relu(conv2, alpha=0.1)\n",
    "\n",
    "def sub_model(features, training, l2_reg = None, ):\n",
    "    conv0 = resnet_block(features, 64, 7, 1, training, l2_reg)\n",
    "    pool0 = pooling(conv0)\n",
    "\n",
    "    block0 = block(pool0, 64, training, l2_reg, stride = 2)\n",
    "    block1 = block(block0, 64, training, l2_reg)\n",
    "    block2 = block(block1, 64, training, l2_reg)\n",
    "\n",
    "    block3 = block(block2, 128, training, l2_reg, stride = 2)\n",
    "    block4 = block(block3, 128, training, l2_reg)\n",
    "    block5 = block(block4, 128, training, l2_reg)\n",
    "    block6 = block(block5, 128, training, l2_reg)\n",
    "    block_special = block(block6, 256, training, l2_reg, stride = 2)\n",
    "\n",
    "    for i in range(22):\n",
    "        block_special = block(block_special, 256, training, l2_reg)\n",
    "\n",
    "    block13 = block(block_special, 512, training, l2_reg, stride = 2)\n",
    "    block14 = block(block13, 512, training, l2_reg)\n",
    "    block15 = block(block14, 512, training, l2_reg)\n",
    "\n",
    "    return block15\n",
    "\n",
    "def resnet(features, labels, mode):\n",
    "    training = False\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        training = True\n",
    "\n",
    "    feature1 = features[..., :3]\n",
    "    feature2 = tf.expand_dims(features[..., 3], -1)\n",
    "    features1 = tf.map_fn(lambda frame: tf.image.per_image_standardization(frame), feature1)\n",
    "    features2 = tf.map_fn(lambda frame: tf.image.per_image_standardization(frame), feature2)\n",
    "\n",
    "    l2_reg = None\n",
    "    \n",
    "    out1 = sub_model(features1, training, l2_reg)\n",
    "    out2 = sub_model(features2, training, l2_reg)\n",
    "    avg1 = tf.keras.layers.GlobalAveragePooling2D()(out1)\n",
    "    avg2 = tf.keras.layers.GlobalAveragePooling2D()(out2)\n",
    "    merge = tf.concat((avg1, avg2), axis = -1)\n",
    "\n",
    "    out = tf.compat.v1.layers.dense(merge, 2048)\n",
    "    out_bn = tf.compat.v1.layers.batch_normalization(out, center=True, scale=True, training=training)\n",
    "    out_relu = tf.nn.relu(out_bn)\n",
    "    logits = tf.keras.layers.Dense(11, activation=None)(out_relu)\n",
    "\n",
    "    predictions = {\n",
    "      \"classes\": tf.argmax(input=tf.nn.softmax(logits), axis=1),\n",
    "      \"probabilities\": tf.nn.softmax(logits),\n",
    "      \"feats\": out_relu\n",
    "    }\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "def train_input_fn():\n",
    "    dataset =  tf.compat.v1.data.TFRecordDataset(train_filenames)\n",
    " \n",
    "    dataset = dataset.map(parser)\n",
    "    dataset = dataset.shuffle(buffer_size=2048)\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    dataset = dataset.repeat(1)\n",
    " \n",
    "    return dataset\n",
    " \n",
    "def eval_input_fn():\n",
    "    dataset =  tf.compat.v1.data.TFRecordDataset(eval_filenames)\n",
    "    dataset = dataset.map(parser)\n",
    "    dataset = dataset.batch(batch_size=batch_size*2)\n",
    "    \n",
    "    return dataset\n",
    " \n",
    "def predict(data, model):\n",
    "    data = np.asarray(data).astype(np.float32)\n",
    "    predict_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(x=data, shuffle = False)\n",
    "    res = list(model.predict(input_fn=predict_input_fn, yield_single_examples=False))\n",
    "    \n",
    "    return res[0]\n",
    "\n",
    "def sharpen(image, P):\n",
    "    def get_sharpW(image, P):\n",
    "        P_lr = cv2.resize(P, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "        if P_lr.shape[0] < image.shape[0]:\n",
    "            image = image[:P_lr.shape[0],:, :]\n",
    "        else:\n",
    "            P_lr = P_lr[:image.shape[0], :]\n",
    "\n",
    "        if P_lr.shape[1] < image.shape[1]:\n",
    "            image = image[:,:P_lr.shape[1], :]\n",
    "        else:\n",
    "            P_lr = P_lr[:,:image.shape[1]]\n",
    "\n",
    "        shape = image.shape\n",
    "        return optimize.lsq_linear(image.reshape(shape[0]*shape[1],3), P_lr.flatten(), (0,1), lsq_solver = 'lsmr').x\n",
    "    \n",
    "    W = get_sharpW(image, P)\n",
    "    P_lr = cv2.resize(P, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_CUBIC)\n",
    "    shape = image.shape\n",
    "    V = P_lr-np.sum(W*image, axis = -1)\n",
    "\n",
    "    V_hr = cv2.resize(V, None, fx=2, fy=2, interpolation = cv2.INTER_CUBIC)\n",
    "    P_hr = P - V_hr\n",
    "    \n",
    "    S_hr = cv2.resize(image, None, fx=2, fy=2, interpolation = cv2.INTER_CUBIC)\n",
    "    I_hr = np.sum(W*S_hr, axis = -1)\n",
    "\n",
    "    out = np.zeros(S_hr.shape)\n",
    "    out[:,:,0] = S_hr[:,:,0] + P_hr - I_hr\n",
    "    out[:,:,1] = S_hr[:,:,1] + P_hr - I_hr\n",
    "    out[:,:,2] = S_hr[:,:,2] + P_hr - I_hr\n",
    "\n",
    "\n",
    "    return out\n",
    "\n",
    "def encode_landCover(img):\n",
    "    w, h = img.shape\n",
    "    u,inv = np.unique(img,return_inverse = True)\n",
    "    colored_img = np.array([classes.get(x, 0) for x in u])[inv].reshape(img.shape)\n",
    "    return np.uint8(colored_img)\n",
    "\n",
    "def example_input_fn(generator):\n",
    "    \"\"\" An example input function to pass to predict. It must take a generator as input \"\"\"\n",
    "\n",
    "    def _inner_input_fn():\n",
    "        dataset = tf.compat.v1.data.Dataset.from_generator(generator, output_types=(tf.float32), output_shapes=(128,128,4)).batch(1)\n",
    "        iterator = dataset.make_one_shot_iterator()\n",
    "        features = iterator.get_next()\n",
    "        return features\n",
    "\n",
    "    return _inner_input_fn\n",
    "\n",
    "def my_service():\n",
    "    start, end = 1, 100\n",
    "    for number in range(start, end):\n",
    "        yield number\n",
    "\n",
    "\n",
    "class TFEstimatorServe(object):\n",
    "\n",
    "    def __init__(self, estimator, input_fn):\n",
    "        self.data = []\n",
    "        self.estimator = estimator\n",
    "        self.input_fn = input_fn(self.data_generator)\n",
    "        self.results = self.estimator.predict(input_fn=self.input_fn, yield_single_examples=True)\n",
    "        self.closed = False\n",
    "    \n",
    "    def data_generator(self):\n",
    "\n",
    "        while not self.closed:\n",
    "            data = self.data.pop(0)\n",
    "            yield data[:,:,:4]\n",
    "\n",
    "    def predict(self, data):\n",
    "\n",
    "        self.data = data\n",
    "        predictions = []\n",
    "        for _ in range(len(data)):\n",
    "            res = next(self.results)\n",
    "            predictions.append((res['feats'], res['classes']))\n",
    "        return predictions\n",
    "\n",
    "    def close(self):\n",
    "        self.closed = True\n",
    "        try:\n",
    "            next(self.predictions)\n",
    "        except:\n",
    "            print(\"Exception in fast_predict. This is probably OK\")\n",
    "\n",
    "FOLDER = './chkp/pop_pred/final/'\n",
    "\n",
    "my_checkpointing_config = tf.estimator.RunConfig(\n",
    "    save_checkpoints_steps = 2048000,\n",
    "    keep_checkpoint_max = 10,\n",
    "    log_step_count_steps = 100)\n",
    "\n",
    "model = tf.estimator.Estimator(resnet, model_dir = FOLDER, config = my_checkpointing_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "civil-median",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2561: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From C:\\Users\\User\\miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2561: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From <ipython-input-2-bb460d96118c>:166: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This is a deprecated API that should only be used in TF 1 graph mode and legacy TF 2 graph mode available through `tf.compat.v1`. In all other situations -- namely, eager mode and inside `tf.function` -- you can consume dataset elements using `for elem in dataset: ...` or by explicitly creating iterator via `iterator = iter(dataset)` and fetching its elements via `values = next(iterator)`. Furthermore, this API is not available in TF 2. During the transition from TF 1 to TF 2 you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)` to create a TF 1 graph mode style iterator for a dataset created through TF 2 APIs. Note that this should be a transient state of your code base as there are in general no guarantees about the interoperability of TF 1 and TF 2 code.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\normalization.py:308: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  '`tf.layers.batch_normalization` is deprecated and '\n",
      "C:\\Users\\User\\miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "C:\\Users\\User\\miniconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  warnings.warn('`tf.layers.dense` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./chkp/pop_pred/final/model.ckpt-23040\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Exception in fast_predict. This is probably OK\n"
     ]
    }
   ],
   "source": [
    "channel_names = ['B1.tif', 'B2.tif', 'B3.tif', 'B4.tif', 'B5.tif', 'B6_VCID_1.tif', 'B7.tif', 'B8.tif']\n",
    "folder = './2021/data/test/'\n",
    "folders = []\n",
    "files = []\n",
    "raw_file_names = []\n",
    "\n",
    "#Choose a desired city and set coordinates\n",
    "city = \"Yakutsk\"\n",
    "file_name = glob.glob(\"./data/test/\"+city+\"/*.tif\")[0][:-6] #SLC\n",
    "for i in range(len(channel_names)):\n",
    "    files.append(file_name + channel_names[i])\n",
    "\n",
    "# x1,x2 = 1500, 3500 #SLC\n",
    "# x1,x2 = 500, 2100 #SanAnt\n",
    "# x1,x2 = 2500, 4500 #Tulsa\n",
    "# x1,x2 = 2000,3920 #LA\n",
    "# x1,x2 = 1700,1400 #NY\n",
    "# x1,x2 = 5000,3000 #Portland\n",
    "# x1,x2 = 4900,1400 #Denver\n",
    "x1,x2 = 1000, 4000 #Yakutsk\n",
    "\n",
    "y1 = x1+1280\n",
    "y2 = x2+1280\n",
    "\n",
    "full_image_with_pop_R = tiff.imread(files[0])[x1:y1,x2:y2]\n",
    "full_image_with_pop_G = tiff.imread(files[1])[x1:y1,x2:y2]\n",
    "full_image_with_pop_B = tiff.imread(files[2])[x1:y1,x2:y2]\n",
    "full_image_with_pop_P = tiff.imread(files[7])[x1*2:y1*2,x2*2:y2*2]\n",
    "LC_map = cv2.imread('./images/unet/out' + city + '_encoded.png', 0)[..., np.newaxis]\n",
    "\n",
    "full_image_with_pop = sharpen(np.stack((full_image_with_pop_R, full_image_with_pop_G, full_image_with_pop_B), axis = 2), \n",
    "                              full_image_with_pop_P)\n",
    "\n",
    "full_image = np.append(full_image_with_pop, LC_map, axis=2)\n",
    "\n",
    "imgs = []\n",
    "for i in range(20):\n",
    "    for j in range(20):\n",
    "        imgs += [full_image[128*i:128*(i+1), 128*j:128*(j+1), :]]\n",
    "\n",
    "del full_image_with_pop, full_image_with_pop_R, full_image_with_pop_G, full_image_with_pop_B, full_image_with_pop_P\n",
    "\n",
    "fast_predict = TFEstimatorServe(model, example_input_fn)\n",
    "out = fast_predict.predict(imgs)\n",
    "fast_predict.close()\n",
    "    \n",
    "del imgs\n",
    "\n",
    "regs = [None]\n",
    "for i in range(1,11):\n",
    "    filename = './chkp/reg/model_'+str(i)+'.sav'\n",
    "    regs += [pickle.load(open(filename, 'rb'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "marked-regulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infred population number:  [93219.4099614]\n"
     ]
    }
   ],
   "source": [
    "pops = 0\n",
    "pops_arr = np.zeros(len(out))\n",
    "for i in range(len(out)):\n",
    "    reg = regs[out[i][1]]\n",
    "    pop = 0\n",
    "    if reg:\n",
    "        pop = reg.predict(out[i][0][np.newaxis,...])\n",
    "    pops += pop\n",
    "    pops_arr[i] = pop\n",
    "    \n",
    "print(\"Infred population number: \", pops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cosmetic-victorian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAD7CAYAAACsV7WPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAv20lEQVR4nO3dfVyUZb748c8wM5BK1JJMEHDMytZ+mFiaxVZDtgUoTgaaKaama6kn0LU9GKFJdCwffqyUy+JWr/SYdlIqBSUatqTlpWKFnj1xLHU9PlCi8aDWgMrTcP/+cJmfCM7cAzIw4/e9r/tFc811cV233Pvl4prrQaMoioIQQohezaunGyCEEMIxCdZCCOEGJFgLIYQbkGAthBBuQIK1EEK4AQnWQgjhBnSurKyp5qgrqxNCuDF9/9u6VF7nHaw6b3NjRZfqcgWXBmshhHAVTU834CqTYC2E8EgajWeFa4fB+siRIxQWFvLTTz/h5eWFwWDg4Ycf5u6773ZF+4QQolM8LVjb/YDxgw8+4MUXXwTg7rvvJiwsDIBXXnmFtWvXdn/rhBCikzRO/M8daOztDRIdHU1ubi59+vRpk37hwgXi4uIwm81OVSYfMAoh1OrqB4z9+t6qOu+588e7VJcr2B0G0el0NDc3t0uvr69Hr9d3W6OEEKKr3KXHrJbdYD1nzhyefPJJIiIiCAgIQKPRUFVVxVdffcWCBQtc1UYhhHCal4eNWdsdBgGorKxkz549VFVV0dLSQmBgIBEREdx8881OVybDIEIItbo6DHKD7+2q8/5Sd6RLdbmCw2B9NUmwFkKo1dVg/SvfO1TnPVv3v12qyxVknrUQwiN52tQ9CdZCCI+k9fKsrY88626EEOKfvNCovpyRl5dHbGwssbGxrFixAoCSkhJMJhNRUVFkZmba8h44cID4+Hiio6NZtGiRbXbdyZMnmTJlCjExMcydO5dz586puB8hhPBAGo1G9aXWhQsXeP3119mwYQN5eXns3buXoqIiUlNTyc7OpqCggP3791NcXAxAcnIyS5YsobCwEEVRyMnJASA9PZ2EhATMZjNDhgwhOzvbYd0SrIUQHqk7VjBarVZaWlq4cOECzc3NNDc34+vry4ABAwgNDUWn02EymTCbzVRUVFBfX8+wYcMAiI+Px2w209TURGlpKdHR0W3SHZExayGER3JmnrXFYsFisbRL9/Pzw8/Pz/ba19eX+fPnM3r0aPr06cN9991HVVUVAQEBtjwGg4HKysp26QEBAVRWVnL27Fl8fX3R6XRt0h2RYC2E8EhajfqBg/Xr15OVldUuPTExkaSkJNvrgwcP8sknn/Dll19y/fXX82//9m8cP368zVCKoihoNBpaWlo6TG/9eik1QzESrIUQHsmZsejp06cTFxfXLv3SXjXArl27iIiI4KabbgIuDmG89957aLVaW57q6moMBgOBgYFUV1fb0mtqajAYDPj7+1NbW4vVakWr1dryOyJj1kIIj+TMbBA/Pz9CQkLaXZcH68GDB1NSUsL58+dRFIWioiLCw8M5duwY5eXlWK1W8vPzMRqNBAcH4+Pjw759+4CLs0iMRiN6vZ4RI0ZQUFAAQG5uLkaj0eH9yApGIUSv1NUVjLf1v0d13qM1f1ed95133mHLli3o9Xruvvtu0tLS+K//+i+WLVtGQ0MDkZGRvPzyy2g0Gg4ePMjixYupq6sjLCyMZcuW4e3tTUVFBSkpKZw+fZqgoCBWrVrFDTfcYLdeCdZCiF6pq8H69v73qs57pOa/ulSXK8iYtRDCI3narnsSrIUQHsmZ2SDuQIK1EMIjXVOHDwghhLvytGEQh38nfPHFF2zYsIEffvihTfrmzZu7rVFCCNFVnnZgrt1gnZGRwcaNGzl+/DiTJ08mLy/P9t6mTZu6vXFCCNFZXhqN6ssd2B0GKS4uZuvWreh0OqZOncrMmTPx9vZm9OjRuHDGnxBCOM1desxq2Q3Wl65hv/XWW3n77beZMWMG/v7+HncKgxDCs3jabBC7dxMTE8PUqVMpKysDYNCgQbz11lv8/ve/bzeGLYQQvUl3HT7QU+z2rBMTExk+fDj9+vWzpQ0fPpwtW7awdu3abm+cEEJ0lqf99S/LzYUQvVJXl5uPvCVSdd5vThZ3qS5XkHnWQgiP5C7DG2pJsBZCeCRP+4BRgrUQwiNJz1oIIdyAZ4VqCdZCCA/lLisT1ZJgLYTwSN2xgvGjjz5i48aNttcnTpxg3LhxPPbYY7aTYkaPHs2CBQsAOHDgAIsWLeLcuXOMGDGC9PR0dDodJ0+eJDk5mdOnTzNw4EAyMjLaTJHuiGeNwAshxD91x6KYp556iry8PPLy8sjIyOCmm27iueeeIzU1lezsbAoKCti/fz/FxRenAiYnJ7NkyRIKCwtRFIWcnBwA0tPTSUhIwGw2M2TIELKzs1XcjxBCeCCtxkv11RmvvvoqCxYs4Mcff2TAgAGEhoai0+kwmUyYzWYqKiqor69n2LBhwMWT0M1mM01NTZSWlhIdHd0m3REZBhFCeCRnhkEsFgsWi6Vdup+fX7sTzgFKSkqor69n9OjR5OfnExAQYHvPYDBQWVlJVVVVm/SAgAAqKys5e/Ysvr6+6HS6NumOSLAWQngkZ/rL69evJysrq116YmIiSUlJ7dI3bdrEjBkzAGhpaWmztL11A7wrpV+6QV4rNUvjJVgLITySM3uDTJ8+nbi4uHbpHfWqGxsbKS0tZfny5QAEBgZSXV1te7+6uhqDwdAuvaamBoPBgL+/P7W1tVitVrRarS2/IzJmLYTwSM58wOjn50dISEi7q6NgfejQIW699Vb69u0LQHh4OMeOHaO8vByr1Up+fj5Go5Hg4GB8fHzYt28fAHl5eRiNRvR6PSNGjKCgoACA3NxcjEajw/uRnrUQwiN11+EDP/74I4GBgbbXPj4+LF++nKSkJBoaGoiMjCQmJga4eNrW4sWLqaurIywsjGnTpgGQlpZGSkoKa9asISgoiFWrVjm+H9l1TwjRG3V11724fzGpzrv1h+1dqssVnBoGaR2jEUKI3k6j0ai+3MEVh0FefvnldmlFRUX88ssvACxbtqz7WiWEEF3kaR/IXTFY33jjjeTm5jJnzhzbIPtXX33FyJEjXdY4IYToLE87MPeKv3xeeuklVq1aRUFBAbfccgtxcXHccMMNxMXFdTjFRQghepNr6gzGiIgI7rrrLtLS0vjb3/6G1Wp1VbuEEKJLtG4ShNVyOKxz44038tZbb3Hbbbe1WTophBC92TXVs77UU089xVNPPdWdbRFCiKvGPUKwerIoRgjhkeTwASGuouavt3WqnO7+J65yS4SnuWam7gkhhDvztKl7EqyFEB7J02aDSLAWQngkGQYRQgg34C5T8tSSYC2E8EieFaolWAshPJT0rIUQwg3ImLUQQrgBT5sN4mm/fIQQArg4Zq32ckZRURHx8fGMHj2apUuXAlBSUoLJZCIqKorMzExb3gMHDhAfH090dDSLFi2iubkZgJMnTzJlyhRiYmKYO3cu586dc1ivBGshhEfqjo2cfvzxR9LS0sjOzmbbtm18//33FBcXk5qaSnZ2NgUFBezfv5/i4mIAkpOTWbJkCYWFhSiKQk5ODgDp6ekkJCRgNpsZMmQI2dnZKu5HCCE8kJcTl8Vi4cSJE+0ui8XS5nt+/vnnjBkzhsDAQPR6PZmZmfTp04cBAwYQGhqKTqfDZDJhNpupqKigvr6eYcOGARAfH4/ZbKapqYnS0lKio6PbpDsiY9ZCCI/kzPDG+vXrycrKapeemJhIUlKS7XV5eTl6vZ45c+Zw6tQpHnnkEQYNGtRm+2iDwUBlZSVVVVVt0gMCAqisrOTs2bP4+vqi0+napDsiwVoI4ZF0ToTr6dOnd3gCVuuRhq2sVit79+5lw4YN9O3bl7lz53Lddde1OXRXURQ0Gg0tLS0dprd+vZSaQ3sdBuudO3cSHh6On58fubm5lJWVERYWxvjx4x1+cyGE6CnO9Kz9/PzaBeaO9O/fn4iICPz9/QF47LHHMJvNaLVaW57q6moMBgOBgYFUV1fb0mtqajAYDPj7+1NbW4vVakWr1dryO2J3zPr111/n7bffpqGhgTfffJNt27Zxxx138Pnnn9s+BRVCiN6oOz5gHDVqFLt27cJisWC1Wtm5cycxMTEcO3aM8vJyrFYr+fn5GI1GgoOD8fHxYd++fQDk5eVhNBrR6/WMGDGCgoICAHJzczEajQ7rttuzLikpYdu2bWi1WoqLi9m8eTPe3t48/fTTjB07VvUNCiGEq3kpV/97hoeHM2vWLBISEmhqauLBBx9k8uTJ3HbbbSQlJdHQ0EBkZCQxMTEAZGRksHjxYurq6ggLC2PatGkApKWlkZKSwpo1awgKCmLVqlUO67YbrK+77jpOnz5t69KfP38eb29vLly4YBscF0KI3qi7prpNmDCBCRMmtEmLiIhg27b2B2kMHjyYjz/+uF16cHAwGzZscKpeuxH3hRdeYMKECcTGxhISEsLUqVOJiIhg165dzJo1y6mKhBDClTxr/aKDYP3oo48yaNAgvvjiC8rLyxk2bBj9+vVj+fLlDB061FVtFEIIpzkzG8QdOBzLCA0NZcaMGa5oixBCXDWeFaplnnWXKXVnXFaXxtff+UItVqeLNJd+6nw9gO6+WOfLyMG3opt42vJsCdZCCI/UHbNBepIEayGER5JhECGEcAMyDCKEEG5AJ8MgQgjR+8kwiBBCuAEZBhFCCDcgwVoIIdyARsashRCi9/O04OZp9yOEEIAsinEPnVhijZfWcZ4OdGoJuAsp539xukzTts+6oSUdk+XmXdPZ7Q56+3N7NchsECGEcAPyAaMQQriB7hoGmTp1KmfOnLEdwPLaa69x7tw5li1bRkNDA6NHj2bBggUAHDhwgEWLFnHu3DlGjBhBeno6Op2OkydPkpyczOnTpxk4cCAZGRn069fP/v10z+0IIUTP0jhxqaUoCsePHycvL892/frXvyY1NZXs7GwKCgrYv38/xcXFACQnJ7NkyRIKCwtRFIWcnBwA0tPTSUhIwGw2M2TIELKzsx3W7TBY79mzh7///e8ArF27ljlz5pCVlUVjY6MTtyiEEK6lUxTVl8Vi4cSJE+0ui8XS5nsePXoUgJkzZ/LEE0+wceNGysrKGDBgAKGhoeh0OkwmE2azmYqKCurr6xk2bBgA8fHxmM1mmpqaKC0tJTo6uk26w/ux9+bKlSvZu3cvzc3NhISEoNFomDx5MkVFRbz22mtywrkQotdyZthg/fr1ZGVltUtPTEwkKSnJ9tpisRAREcErr7xCU1MT06ZNY9asWQQEBNjyGAwGKisrqaqqapMeEBBAZWUlZ8+exdfX1zaM0pruiN1gvXPnTvLy8mhsbOSRRx5h586d6PV6jEYj48aNc/wvIIQQPcSZ4Y3p06cTFxfXLt3Pz6/N63vuuYd77rnH9nrChAmsXr2a4cOH29IURUGj0dDS0oJGo2mX3vq1TVs1jltrN1grikJtbS3nz5/nwoUL1NXV8atf/Yr6+nqampocfnMhhOgpXor6Txj9/PzaBeaO7N27l6amJiIiIoCLMTI4OJjq6mpbnurqagwGA4GBgW3Sa2pqMBgM+Pv7U1tbi9VqRavV2vI7vB97bz733HNERUUxbtw4kpOTmTlzJitXriQhIYHx48c7/OZCCNFTvJy41KqtrWXlypU0NDRQV1fH1q1befHFFzl27Bjl5eVYrVby8/MxGo0EBwfj4+PDvn37AMjLy8NoNKLX6xkxYgQFBQUA5ObmYjQaHdatURT7v37q6+uxWq3069ePQ4cOsWvXLgYPHsyDDz7oxC1e1FRz1OkyneLCRTG9XWcWTdQvW9SpuvRPjHa6jCyK6RpPXhSj739bl8pvD5ysOq/ppw9V533zzTcpLCykpaWFhIQEpk+fzp49e2xT9yIjI3n55ZfRaDQcPHiQxYsXU1dXR1hYGMuWLcPb25uKigpSUlI4ffo0QUFBrFq1ihtuuMFuvQ6D9dUkwdr1JFh7NgnWV/bpzeqDdWyl+mDdUzxyUUxnlli7w8PbGdbvdjldRm+K7lRd2rCHOlVOdJ6nPrdXgwbP2hzEI4O1EEJ42oo/CdZCCI8kwVoIIdyADIMIIYQb0EqwFkKI3s9LgrUQQvR+Xh52+oAEayGER5IxayGEcAMyG0QIIdyARiM9ayGE6PW0EqxdS2m84HQZj12C25k9TzqhKc/xqRUd0YQOdrqM1lN/VqLHeUmwFkKI3k+GQYQQwg1Iz1oIIdyAipOy3IoEayGER9J6tfR0E64qT5uKKIQQwMWetdqrM1asWEFKSgoAJSUlmEwmoqKiyMzMtOU5cOAA8fHxREdHs2jRIpqbmwE4efIkU6ZMISYmhrlz53Lu3DmH9TkM1jt37mTRokX87ne/47nnnmPRokUUFhZ27u6EEMJFNBpF9eWsPXv2sHXrVuDi0YepqalkZ2dTUFDA/v37KS4uBiA5OZklS5ZQWFiIoijk5OQAkJ6eTkJCAmazmSFDhpCdne2wTrvB+q233uI//uM/GDlyJLNmzWLGjBmMHDmSjz/+mBUrVjh9g0II4SpeGkX15Yyff/6ZzMxM5syZA0BZWRkDBgwgNDQUnU6HyWTCbDZTUVFBfX09w4YNAyA+Ph6z2UxTUxOlpaVER0e3SXfE7ph1QUEBn332GV5ebWP62LFjGTt2LC+99JJTNymEEK6i8VIfhC0WCxaLpV26n58ffn5+bdKWLFnCggULOHXqFABVVVUEBATY3jcYDFRWVrZLDwgIoLKykrNnz+Lr64tOp2uT7ojdYO3j48NPP/3ELbfc0ib95MmTeHt7O/zmQgjRU5wZi16/fj1ZWVnt0hMTE0lKSrK9/uijjwgKCiIiIoItW7YA0NLSguaSyhRFQaPRXDG99WvbtjpurN1gnZKSwpQpU7j11lsJCAhAo9FQVVXF8ePHWbZsmcNvLoQQPcVLq342yPTp04mLi2uXfnmvuqCggOrqasaNG8cvv/zC+fPnqaioQKvV2vJUV1djMBgIDAykurrall5TU4PBYMDf35/a2lqsVitardaW3xG7wfo3v/kNZrOZsrIyqqqqaGlpITAwkPDw8E71rJW6M06X6czp3Lr7n3C6jDtoLv3U6TJNuQVOl9m57SanywA8zJtOl+mz7C+dqksIR5wZi+5ouKMj69ats/33li1b+Oabb0hPTycqKory8nJCQkLIz89n/PjxBAcH4+Pjw759+xg+fDh5eXkYjUb0ej0jRoygoKAAk8lEbm4uRqPRYd12g/XJkycBCA4OJjg42JZeU1MD0G54RAgheguNiyYm+/j4sHz5cpKSkmhoaCAyMpKYmBgAMjIyWLx4MXV1dYSFhTFt2jQA0tLSSElJYc2aNQQFBbFq1SqH9WgURbnirx+TycTx48cxGAxcnk2j0bBjxw6nbqrx+F6n8oP0rC/V/PU2p8u4tGf9xGmny0jPWlyJvv9tXSp/9O4o1Xlv+5+/dqkuV7Dbs/7www9JSEggLS2N4cOHu6pNQgjRZc7MBnEHdv9Q8PX1ZenSpeTm5rqoOUIIcXV09wpGV3O4N8jQoUMZOnSoK9oihBBXjZfOs/YGkY2chBAeyV16zGpJsBZCeCRPG7OWYC2E8EiumrrnKhKshRAeSY71EkIIN+Clk2DdaR576riTOrO4BaBp22dXuSUdi/t5Z6fKWRLfucotEaLzZBhECCHcgQyDCCFE7yc9ayGEcAMSrIUQwg14WrC2ezvNzc2sX7+e5cuXs3dv2x3z/vSnP3Vrw4QQois0OvWXO7AbrJcsWcKBAwcwGAwsXLiQv/zl/29nWVRU1O2NE0KITvNy4nIDdn+n7N+/n23bLk4ze/LJJ3n22We57rrrePbZZ9vtby2EEL3JNTUMoigK58+fB8Df3593332X999/n23btqk64FEIIXpMN/Ws33rrLcaMGUNsbKztmK+SkhJMJhNRUVFkZmba8h44cID4+Hiio6NZtGgRzc3NwMVTuKZMmUJMTAxz587l3Llzqm7nip555hni4uLYs2cPADfffDPvvvsumZmZHDlyxLk7FEIIF9J4aVRfan3zzTd89dVXbNu2jU8++YQNGzZw8OBBUlNTyc7OpqCggP3791NcXAxAcnIyS5YsobCwEEVRyMnJASA9PZ2EhATMZjNDhgwhOzvbYd12g/XTTz/N22+/zYABA2xpt99+O9u3b+fFF19UfYNCCOFy3dCzHjlyJO+//z46nY7Tp09jtVqxWCwMGDCA0NBQdDodJpMJs9lMRUUF9fX1DBs2DID4+HjMZjNNTU2UlpYSHR3dJt0Rhwfmtp5i3np4bquoKPXnm3WFp56n2Bn+6/Y7XcarE8NVNdP+j9NlALTBgztVTojuoNGpf/YtFgsWi6Vdekennuv1elavXs3atWuJiYmhqqqKgIAA2/sGg4HKysp26QEBAVRWVnL27Fl8fX3R6XRt0h2xG6xnz559VQ/MFUIIl3FieGP9+vVkZWW1S09MTCQpKald+rx583juueeYM2cOx48fb/MZnqIoaDQaWlpaOkxv/XopNZ8ByoG5QgiP5MxY9PTp04mLi2uXfnmv+siRIzQ2NnLXXXfRp08foqKiMJvNaLVaW57q6moMBgOBgYFUV1fb0mtqajAYDPj7+1NbW4vVakWr1dryOyIH5gohPJMTY9Z+fn6EhIS0uy4P1idOnGDx4sU0NjbS2NjIjh07mDRpEseOHaO8vByr1Up+fj5Go5Hg4GB8fHzYt28fAHl5eRiNRvR6PSNGjKCgoACA3NxcjEajw9uRA3OFEJ7JiZ61WpGRkZSVlfHkk0+i1WqJiooiNjYWf39/kpKSaGhoIDIykpiYGAAyMjJYvHgxdXV1hIWFMW3aNADS0tJISUlhzZo1BAUFsWrVKod1axQXrm5pqjnqqqp6tc7uZ3193P91uowrP2Dss+wvjjMJoZK+/21dKm95Tv0kCL93/9qlulzBTVbFCyGEk7qhZ92TJFgLITySp62ylmAthPBM0rMWQgg3IMFaCCHcgJdnbbsnwbpVi7Vz5by0jvNcJWemhzldpnj7TU6X6bPsdafLCNHbaHQSrIUQoveTYRAhhHADHnb6gARrIYRnkp61EEK4AQ8L1k7/nSCHDggh3IFGp1V9uQO7PeupU6e2WwW0f/9+22Yk77//fve1TAghuuJaGrOOjo7m3XffZf78+YSEhKAoCq+88gqJiYmuap8QQnTOtTQM8swzz/Dee+/xySefcPLkSe6//3769evHyJEjGTlypKvaKIQQzvPyUn+5AYetvOOOO1i3bh0HDx5k3rx5NDY2uqJdQgjRNV4a9ZcbUDUbxNvbm5SUFHbv3s2nn37a3W3qGS5cidjZQ4CbcgucLvPYe/d3qi7xT26wslVcwbU0Zn35ieYDBw4kMTHRln7LLbd0X8uEEKILumuWR1ZWFp999hlw8eSYhQsXUlJSwrJly2hoaGD06NEsWLAAgAMHDrBo0SLOnTvHiBEjSE9PR6fTcfLkSZKTkzl9+jQDBw4kIyODfv362a3X6dPNLz2dV043F0L0Wt0wvFFSUsKuXbvYunUrGo2GWbNmkZ+fT0ZGBhs2bCAoKIjZs2dTXFxMZGQkycnJLF26lGHDhpGamkpOTg4JCQmkp6eTkJBAbGwsf/7zn8nOziY5Odn+7dh788MPP2TgwIGsXLmSoqIiioqK2LFjh+2rEEL0Whov9ZdKAQEBpKSk4O3tjV6v5/bbb+f48eMMGDCA0NBQdDodJpMJs9lMRUUF9fX1DBs2DID4+HjMZjNNTU2UlpYSHR3dJt0Ruz3r1tPNP/roI4YPH676hoQQosc50bO2WCxYLJZ26X5+fm1OOB80aJDtv48fP85nn33GM888Q0BAgC3dYDBQWVlJVVVVm/SAgAAqKys5e/Ysvr6+6HS6NumOyOnmQgjP5MSUvPXr15OVldUuPTExkaSkpHbphw8fZvbs2SxcuBCtVsvx48dt77UOE7e0tLRZVNia3vr1UmqOIJO9QYQQnsmJMxinT59OXFxcu/RLe9Wt9u3bx7x580hNTSU2NpZvvvmG6upq2/vV1dUYDAYCAwPbpNfU1GAwGPD396e2thar1YpWq7Xld0SCtRDCM+nUh7fLhzuu5NSpU7zwwgtkZmYSEREBQHh4OMeOHaO8vJyQkBDy8/MZP348wcHB+Pj4sG/fPoYPH05eXh5GoxG9Xs+IESMoKCjAZDKRm5uL0Wh0fDuq70YIIdxJN8wGee+992hoaGD58uW2tEmTJrF8+XKSkpJoaGggMjKSmJgYADIyMli8eDF1dXWEhYXZ9lVKS0sjJSWFNWvWEBQUxKpVqxzWrVFa5+S5QFPNUVdV5ZEuvDzH6TL6J8c4Xaazi3Y8kiyK6TH6/rd1qfz5v8xXnbfvnLe6VJcrSM9aCOGZ3GTPD7UkWPeA5q+3dapcZ3rJomsuvNK5HSb7vL7mKrdEOEvjJnt+qCXBWgjhmbSeFd48626EEKKVDIMIIYQbcGKetTuQYC2E8EzSsxZCCDfgYftZ272b5uZmNm3axOnTp2lsbCQrK4vZs2ezevVqGhoaXNVGIYRw3rV0rNdLL71EaWkpXl5erFixgoqKChISEjh79iypqamuaqMQQjhPq1V/uQG7wyD/+Mc/2L59O3Bx85LWDbcjIyMZM0bm/AohejE36TGrZfdu+vbty+HDhwG47bbbOHXqFACVlZV4e3t3f+uEEKKzPGwYxG7POiUlhRkzZnDvvffSp08fJk6cSHh4ON999x3p6emuaqMQQjjPwz5gtBus77nnHsxmMyUlJZSXlzNw4ED69+/PK6+8QmBgoKvaKP5JNljqGmvFQafL6J8Y3Q0tES7hJj1mtVSdbj5kyBCGDBliS29paeHkyZNyurkQove6lnrWcrq5EMJtXUt7g3z44YckJCSQlpYmB+YKIdyLhw2D2L2b1tPNc3NzXdQcIYS4SrpxNkhdXR1jx47lxIkTAJSUlGAymYiKiiIzM9OW78CBA8THxxMdHc2iRYtobm4GLg4xT5kyhZiYGObOncu5c+cc346jDEOHDuXf//3fnb4ZIYToURov9ZcTvv32WyZPnmw70by+vp7U1FSys7MpKChg//79FBcXA5CcnMySJUsoLCxEURRycnIASE9PJyEhAbPZzJAhQ8jOznZYr2f9nSCEEK26qWedk5NDWlqa7UTysrIyBgwYQGhoKDqdDpPJhNlspqKigvr6eoYNGwZAfHw8ZrOZpqYmSktLiY6ObpPuiGeNwAshRCsnPmC0WCxYLJZ26R2dev7666+3eV1VVUVAQIDttcFgoLKysl16QEAAlZWVnD17Fl9fX3T/PH29Nd0RCdZCCM/kxPDG+vXrycrKapeemJhIUlKS3bItLS1oLtk7u3W23JXSW7+2aaqKvbclWAshPJMTwxvTp08nLi6uXfrlveqOBAYGUl1dbXtdXV2NwWBol15TU4PBYMDf35/a2lqsVitardaW3xEZsxZCeCSNRqv68vPzIyQkpN2lJliHh4dz7NgxysvLsVqt5OfnYzQaCQ4OxsfHh3379gGQl5eH0WhEr9czYsQICgoKAMjNzcVoNDqsR3rWPUCWjfcMbfBg5wt1pozoHVw0z9rHx4fly5eTlJREQ0MDkZGRxMTEAJCRkcHixYupq6sjLCyMadOmAZCWlkZKSgpr1qwhKCiIVatWOaxHo7QuTXSBppqjrqpKCOHm9P1v61L5+j0fqs57XcTkLtXlCtKzFkJ4pmtpubkQQrita2kjJyGEcFte7nFcl1oSrIUQnula6lk3NzeTm5vLddddR3R0NMuWLaO0tJQhQ4bw0ksvceONN7qomUII4SQP23XP7myQlJQUzp8/T2NjIz///DNDhw5l4sSJ7Nixg++++47Vq1c7VZnMBhFCqNXl2SDfFqjOe1147z8A3G7P+rvvvmP79u1YrVYiIyPZtGkTAHfccQfjxo1zSQOFEKIzNFp9TzfhqrIbrL28vDh27Bi1tbXU1tZy4sQJQkJCOHPmjG1fViGE6JWupTHr5ORkZsyYQUtLC3/84x957rnnuPPOO/mf//kf5s2b56o2CiGE866lMevL1dTUsHfvXgYNGsTtt9/udGW9ecxaqTvTqXIaX/+r3BIhBHR9zLrhYLHqvD6DI7tUlyuoOt38UkOHDrW9J6ebCyF6rWtpnnVHp5u3ktPNhRC92rW03FxONxdCuCuNh33AKKebCyE8Uzeebt4THP6dMHToUNs4tRBCuA0P61l71qCOEEK0upY+YBRCCLflYT1rz7obIYT4J41Wp/pyxvbt2xkzZgxRUVF88MEH3dT69qRnLYTwTN3wwWFlZSWZmZls2bIFb29vJk2axP33388dd9xx1eu6nARrIYRncmIYxGKxYLFY2qX7+fm1OeG8pKSEBx54wLY9dHR0NGazmcTExC431xGXBuuuLh/tVr25bUIIp+kNg1Tn/cuf/kRWVla79MTERJKSkmyvq6qqCAgIsL02GAyUlZV1raEqSc9aCHHNmz59OnFxce3SL+1VA7S0tKDRaGyvFUVp87o7SbAWQlzzLh/uuJLAwED27t1re11dXY3BYOjOptnIbBAhhFDpN7/5DXv27OHMmTNcuHCBv/71rxiNRpfULT1rIYRQ6eabb2bBggVMmzaNpqYmJkyY4LIV3k7tZy2EEKJnyDCIEEK4AQnWQgjhBiRYCyGEG5BgLYQQbqDHg3VnN0Wpq6tj7NixnDhxQlX+rKwsYmNjiY2NZeXKlarreeuttxgzZgyxsbGsW7dOdTmAFStWkJKSojr/1KlTiY2NZdy4cYwbN45vv/3WYZmioiLi4+MZPXo0S5cuVVXPRx99ZKtj3LhxDB8+nNdee81huby8PNu/4YoVK1TV9c477xAdHY3JZGLNmjV2817+My0pKcFkMhEVFUVmZqbqcgALFy5ky5Ytqsts3ryZsWPHYjKZePnll2lsbFRV7j//8z+JjY1lzJgxrFixot3xd1dqH8DGjRuZOnWqqnpefvlloqKibD+zzz//XFW5v//970ycOJHY2FhefPHFDu/r0jLFxcVtno0HHniA2bNnq6pr165dPPHEE4wdO5aFCxc6rAtgy5YtjBkzBpPJxNKlS2lubu6wLgEoPeinn35SRo0apZw9e1Y5d+6cYjKZlMOHDzss99///d/K2LFjlbCwMOXHH390mH/37t3K008/rTQ0NCiNjY3KtGnTlL/+9a8Oy3399dfKpEmTlKamJuXChQvKqFGjlCNHjqi6t5KSEuX+++9XXnrpJVX5W1palIceekhpampSlV9RFOWHH35QHnroIeXUqVNKY2OjMnnyZOVvf/ub6vKKoij/+Mc/lMcff1w5ffq03Xznz59X7rvvPuX06dNKU1OTMmHCBGX37t12y+zevVsZO3asUltbqzQ3NyuzZ89WCgsLO8x7+c/0woULSmRkpPLDDz8oTU1NysyZMzu8t8vL/fTTT8rs2bOVoUOHKp988omquo4ePao8/vjjSm1trdLS0qIsXLhQWbduncNyP/zwg/L4448r586dU5qbm5Wnn35a2blzp90yrQ4fPqw8/PDDyjPPPOOwHkVRlLFjxyqVlZVX/LfuqFxtba3y4IMPKgcOHFAURVEWLFigfPDBB6rapyiKUlVVpfz2t79Vjh07pqqNRqNR+d///V9FURQlKSlJycnJsVvmyJEjysMPP2y7r7S0NGXt2rV27/Fa1qM960s3Renbt69tUxRHcnJySEtLU71yKCAggJSUFLy9vdHr9dx+++0dntx+uZEjR/L++++j0+k4ffo0VquVvn37Oiz3888/k5mZyZw5c1S1D+Do0aMAzJw5kyeeeIKNGzc6LPP5558zZswYAgMD0ev1ZGZmEh4errpOgFdffZUFCxbg7+9vN5/VaqWlpYULFy7Q3NxMc3MzPj4+dst8//33PPTQQ/j6+qLVann44Yf54osvOsx7+c+0rKyMAQMGEBoaik6nw2QydfhsXF5u+/bt/Pa3v2X06NFXbNflZby9vUlLS8PX1xeNRsOdd97Z4fNxebnQ0FA+/fRT+vbti8Vioa6urt0quI6e1cbGRpYsWcK8efNUte/ChQucPHmS1NRUTCYTq1evpqWlxWG53bt3M2zYMAYPHgzA4sWLefzxxx22r9XKlSuZNGkSt956q8O64OIzUldXh9VqpaGhod3zcXmZQ4cOMWzYMNvrUaNGXfH5ED28KKazm6K8/vrrTtUzaND/39Dl+PHjfPbZZ3z44Yeqyur1elavXs3atWuJiYnh5ptvdlhmyZIlLFiwgFOnTqluo8ViISIigldeeYWmpiamTZvGwIEDefDBB69Ypry8HL1ez5w5czh16hSPPPIIv//971XXWVJSQn19vd3A1srX15f58+czevRo+vTpw3333ce9995rt0xYWBhvvPEGs2fPpk+fPhQVFXU4TADtf6YdPRuVlZUOy82aNQuAffv2XbFdl5cJDg4mODgYgDNnzvDBBx+wbNkyh+Xg4vORk5PDihUrGDp0qC0w2ivzxz/+kfHjxxMSEqKqfTU1NTzwwAOkpaVx/fXXM3v2bD7++GMmTpxot1x5eTl9+/ZlwYIFHD16lHvvvbfdsNyV/r90/Phxvvnmmyu+31H6q6++ytSpU/H19SUkJISYmBi7ZQYPHszy5cs5deoUBoMBs9lMTU1Nh/WJHh6zdvWmKIcPH2bmzJksXLiww97ClcybN489e/Zw6tQpcnJy7Ob96KOPCAoKIiIiwqm23XPPPaxcuZLrr78ef39/JkyYQHFxsd0yVquVPXv28MYbb7B582bKysrYunWr6jo3bdrEjBkzVOU9ePAgn3zyCV9++SU7d+7Ey8uL9957z26ZiIgI4uPjmTp1KrNmzWL48OHo9XpV9fXEhjmVlZVMnz6d8ePHc//996suN3HiRL7++mv69+/f4c5tl9q9ezenTp1i/Pjxqr9/aGgof/7znzEYDPTp04epU6c6fDbg4vOxa9cuXnzxRbZs2cKFCxd45513VNW5efNmEhIS8Pb2VpW/urqajIwM8vPz2bVrF+Hh4R3+wrvUwIED+cMf/sDcuXOZMmUKv/71r1U/H9eiHg3WgYGBVFdX215356Yo+/bt49lnn+UPf/hDh7trdeTIkSMcOHAAgD59+hAVFcWhQ4fslikoKGD37t2MGzeO1atXU1RUxBtvvOGwrr1797Jnzx7ba0VR0Ons/+HTv39/IiIi8Pf357rrruOxxx5TvV1jY2MjpaWlPProo6ry79q1i4iICG666Sa8vb2Jj4/nm2++sVumrq6OqKgotm/fzoYNG/D29iY0NFRVfa58NuDiz3rSpEnExcXxwgsvqCpz6tQpWw9ep9MRGxvr8PnIz8/n8OHDjBs3jsWLF7N//36Hfw0dOnSIwsJC22s1zwZcfD7Cw8MJDQ1Fq9UyevRo1c/Hjh07GDNmjKq8cPH5vfPOO/mXf/kXvLy8mDhxosPno6GhgaFDh5Kbm8umTZu4+eabVT8f16IeDdau2hTl1KlTvPDCC2RkZBAbG6u63IkTJ1i8eDGNjY00NjayY8cOhg8fbrfMunXryM/PJy8vj3nz5vHoo4+SmprqsK7a2lpWrlxJQ0MDdXV1bN26td344uVGjRrFrl27sFgsWK1Wdu7cSVhYmKp7O3ToELfeequqMXi4+CdrSUkJ58+fR1EUioqKuPvuu+2WOXHiBP/6r/9Kc3MztbW1fPzxx6qGXADCw8M5duwY5eXlWK1W8vPzu23DnLq6On73u98xf/58Zs6cqbpcbW0tycnJWCwWFEWhsLDQ4fOxbNkyPvvsM/Ly8li6dClDhgzhzTfftFtGURTeeOMNfvnlF5qamti8ebPDZwPgoYce4rvvvrMNx3355Zeqno8zZ85QX1/vVOC88847KSsrsw1j7Nixw+Hzcf78eZ599lnq6upobGxk48aNTv2CuNb06Ji1qzZFee+992hoaGD58uW2tEmTJjF58mS75SIjIykrK+PJJ59Eq9USFRXlVLB3xqhRo/j222958sknaWlpISEhgXvuucdumfDwcGbNmkVCQgJNTU08+OCDqv+8/vHHHwkMDFTdvoceeojvv/+e+Ph49Ho9d999N88//7zdMoMHDyYqKoonnngCq9XKs88+6zCYtfLx8WH58uUkJSXR0NBAZGRkuzHQq+Xjjz+mpqaGdevW2aZnPvroo8yfP99uuTvvvJPnn3+eSZMmodVqGTFihOphJWcMHjyY559/nsmTJ9Pc3ExUVBRjx451WC4oKIjXXnuNOXPm0NDQwF133cVLL73ksNyJEyecejYAbr/9dubPn8+0adPQarUMGDDA4XTQX/3qV7zwwgs8/fTTNDc326ZOio7JRk5CCOEGenxRjBBCCMckWAshhBuQYC2EEG5AgrUQQrgBCdZCCOEGJFgLIYQbkGAthBBuQIK1EEK4gf8HI+Ro/E02cTYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np; np.random.seed(0)\n",
    "import seaborn as sns; sns.set_theme()\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "out_matr = np.reshape(pops_arr, (20,20))\n",
    "ax = sns.heatmap(out_matr, cmap = sns.cm.rocket_r)\n",
    "\n",
    "norm = Normalize(vmin=min(pops_arr), vmax=max(pops_arr))\n",
    "rgba_values = sns.cm.rocket_r(norm(out_matr))\n",
    "\n",
    "out_img = full_image.copy()\n",
    "\n",
    "for i in range(20):\n",
    "    for j in range(20):\n",
    "        temp = out_img[128*i:128*(i+1), 128*j:128*(j+1), :3]\n",
    "        rmap = np.zeros((128,128,3))\n",
    "        rmap += 255*rgba_values[i,j,:3]\n",
    "        dst = cv2.addWeighted(temp, 1, rmap[:,:,::-1], 0.5, 0)\n",
    "        out_img[128*i:128*(i+1), 128*j:128*(j+1), :3] = dst\n",
    "\n",
    "out_img[out_img>255] = 255\n",
    "cv2.imwrite('./images/unet/out'+city+'_reg.png', np.uint8(out_img)[:,:,:3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-federal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
